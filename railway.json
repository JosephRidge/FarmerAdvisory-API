{
  "build": {
    "builder": "nixpacks",
    "config": {
      "buildCommand": "pip install --upgrade pip && pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu/ && pip install -r requirements.txt"
    }
  }
}