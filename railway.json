{
  "build": {
    "builder": "nixpacks",
    "config": {
      "buildCommand": "pip install --upgrade pip && pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu/ && pip install -r requirements.txt",
      "startCommand": "uvicorn app:app --host 0.0.0.0 --port ${PORT:-8000}"
    }
  }
}